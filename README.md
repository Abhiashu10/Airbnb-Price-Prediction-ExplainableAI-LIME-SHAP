
# Hi, I'm Ashutosh ! üëã
In this project, we are utilizing ML models to forecast Airbnb property pricing and identify the key attributes that will have the biggest effects on the house.
Additionally, we are attempting to understand the model by using explainable AI LIME and SHAP. There are two other sections in the code in addition to the three machine learning models:

1.) Prediction explanation with LIME
2.) Prediction explanation with SHAMP




# AirBnb Price Prediction- ML and Explainable AI (LIME and SHAP)

We use the Inside Airbnb dataset to identify significant trends in customer interest and predict the pricing of rentals in the US and Europe. This problem is similar to a classical use case of machine learning: house price prediction. We can then provide solutions to business difficulties.
There are several questions that we want to find answers to:

‚óè	How to predict the price for each listing?

‚óè	Can we find out how the features of listings affect the price locally and globally?

## üîó Links
[Code link](https://github.com/Abhiashu10/Airbnb-Price-Prediction--LIME-and-SHAP/blob/d024360cda85a95a689e8876cc4756bfac2e4c45/Airbnb%20Price%20Prediction-Explainable%20AI.ipynb)

## Features
There are 27 total Input features in the dataset: -

‚û¢	accommodates: The maximum capacity of the listing.   
‚û¢	amenities: Furniture that the listing has.   
‚û¢	availability_365: The availability of the listing 365 days in the future as determined by the calendar. Note a listing may not be available because it has been booked by a guest or blocked by the host.   
‚û¢	bedrooms: The number of bedrooms.  
‚û¢	beds: The number of bed(s).  
‚û¢	calculated_host_listings_count: The number of listings the host has in the current scrape, in the city/region geography.  
‚û¢	host_has_profile_pic: boolean [t=true; f=false].  
‚û¢	host_id: Airbnb's unique identifier for the host/user.  
‚û¢	host_identity_verified: boolean [t=true; f=false].   
‚û¢	host_name: Name of the host. Usually just the first name(s).   
‚û¢	host_response_rate: the rate the host respond to their messages.   
‚û¢	host_response_time: the amount of time the host takes to reply to their messages.   
‚û¢	id: Airbnb's unique identifier for the listing.    
‚û¢	instant_bookable: [t=true; f=false]. Whether the guest can automatically    book the listing without the host requiring to accept their booking request.   
‚û¢	last_review: The date of the last/newest review.   
‚û¢	latitude: Uses the World Geodetic System (WGS84) projection for latitude and longitude.    
‚û¢	longitude: Uses the World Geodetic System (WGS84) projection for latitude and longitude.     
‚û¢	maximum_nights: maximum number of night stay for the listing (calendar rules may be different).    
‚û¢	minimum_nights: minimum number of night stay for the listing (calendar rules may be different).    
‚û¢	name: Name of the listing.     
‚û¢	neighborhood: the neighborhood of the listing.    
‚û¢	number_of_reviews: The number of reviews the listing has.    
‚û¢	property_type: Self-selected property type. Hotels and Bed and Breakfasts are described as such by their hosts in this field.    
‚û¢	reviews_per_month: The number of reviews the listing has over the lifetime of the listing.    
‚û¢	review_scores_rating: average rating.    
‚û¢	room_type: [ Entire home/apt | Private room | Shared room | Hotel ]

# Target variable:
price: the daily price of a listing. 


# Categorical features
We get categorical features, evaluate them and convert them to numerical features. Those categorical features are amenities, host_has_profile_pic, host_identity_verified, host_name, host_response_rate, host_response_time, instant_bookable, last_review, name, neighborhood, price, property_type and room_type.
amenities: because they are lists of amenities the listings have, we try to convert them to the number of amenities those listings have

host_has_profile_pic, host_identity_verified, instant_bookable: because these features have 2 boolean values ‚Äòt‚Äô, ‚Äòf‚Äô so we convert them into binary values ‚Äò0‚Äô, ‚Äò1‚Äô.

# Numerical features
We get all numeric features, including categorical features that we turn into numeric features. Then we deal with outliers. At first, we try to use InterQuartile Range to detect and remove outliers of each feature that are outside of Q1 - 1.5 * IQR  and Q3 + 1.5 * IQR. However, this step removes so many outliers that the dataset reduces to only 50,000 observations left and decreases the accuracies of models we build later. So we decided to modify the range a little bit. We calculate the upper bound (97.5%) and lower bound (2.5 %) of values of each feature, and remove observations that have values outside those bounds. After doing this step, the remaining dataset has around 150,000 observations, which is pretty suitable to train and test ML models.









